{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Bayesian Optimization\n",
    "# Optimizing the SGD Learning Rate when Training a Neural Network\n",
    "\n",
    "### Roger Garrida\n",
    "### Akhil Lohia\n",
    "### Daniel Velasquez"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction \n",
    "\n",
    "\n",
    "Training a neural network can be a difficult task. In particular, due to the large number of hyperparameters that need to be tunned, e.g. number of layers, number of hidden units, batch size among other. In this project, we focus on one particular hyperparameter that influence directly the success of the learning procedure: The stochastic gradient descent **learning rate **. We use bayesian optimization to tune the learning rate and compare the results with a grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Required libraries\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "import pandas as pd\n",
    "import math as mat\n",
    "import scipy\n",
    "from scipy.stats import norm\n",
    "from scipy import optimize\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gaussian_kernel(x1,x2,noise,length): #Generate the kernel (cov) of the Gaussian Process\n",
    "    n1 = x1.shape[0]\n",
    "    n2 = x2.shape[0]\n",
    "    kernel = np.zeros((n1,n2))\n",
    "    for i in range(n1):\n",
    "        for j in range(n2):\n",
    "            kernel[i,j] = noise**2*mat.exp(-0.5*((x1[i]-x2[j])/length)**2)\n",
    "    return kernel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LLH_GP(x,y,m,noise,length, sf = 0): #Compute the likelihood of the data (add sf if consider noise)\n",
    "    ker = gaussian_kernel(x,x, noise, length)\n",
    "    ker = ker+np.diag([sf]*len(x))\n",
    "    return 1/2*(mat.log(np.linalg.det(ker))+np.dot(np.dot(np.transpose(y-m),\n",
    "                                                       np.linalg.inv(ker)),(y-m)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opt_hyparams(x,y): #Find the hyperparameters that optimize LLH without noise\n",
    "    ini = np.array([0,1,1])\n",
    "    opt = optimize.minimize(lambda params: LLH_GP(x, y, params[0], params[1], params[2]),\n",
    "                            ini)\n",
    "    params = opt.x\n",
    "    m = params[0]\n",
    "    noise = abs(params[1])\n",
    "    length = abs(params[2])\n",
    "    sf = 0\n",
    "    return m, noise, length, sf  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def opt_hyparams_noise(x,y): #Find the hyperparameters that optimize LLH with noise\n",
    "    ini = np.array([0,1,1,1])\n",
    "    opt = optimize.minimize(lambda params: LLH_GP(x, y, params[0], \n",
    "                                                  params[1], params[2], params[3]),ini)\n",
    "    params = opt.x\n",
    "    m = params[0]\n",
    "    noise = abs(params[1])\n",
    "    length = abs(params[2])\n",
    "    sf = abs(params[3])\n",
    "    return m, noise, length, sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Generates the mean and covariance of the posterior distribution in the given grid (xn) \n",
    "#from data (x,y) and the optimized parameters (mean->m, noise, length, noise in y -> sf)\n",
    "def gp_posterior(x, y, xn, m, noise, length, sf = 0): \n",
    "    kxx = gaussian_kernel(x, x, noise = noise, length = length)\n",
    "    kxxn = gaussian_kernel(x, xn, noise = noise, length = length)\n",
    "    kxnx = gaussian_kernel(xn, x, noise = noise, length = length)\n",
    "    kxnxn = gaussian_kernel(xn, xn, noise = noise, length = length)\n",
    "    core = np.linalg.inv(kxx + np.diag([sf]*len(x)))\n",
    "    En = np.dot(np.dot(kxnx, core), y)\n",
    "    covn = kxnxn - np.dot(np.dot(kxnx, core), kxxn)  \n",
    "    \n",
    "    return En, covn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_posterior(x, E, cov):\n",
    "    data = pd.DataFrame({'x': x})\n",
    "    data['Mean'] = E\n",
    "    data['StdDev'] = np.diag(cov)\n",
    "    #Generate the 5 samples as multivariate normals with 0 mean and covariance sigma\n",
    "    for i in range(5):\n",
    "        data['y'+str(i)] = np.random.multivariate_normal(E, cov)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Neural Network Architecture and Dataset\n",
    "\n",
    "Our goal is to perform classification on the MNIST dataset. To do so, we build a neural network with one hidden layer and a fixed number of hidden units. We divide the dataset in training and test sample. We define a function that trains the network as a function of the learning rate and returns a measure of accuracy estimated using the test sample. The accuracy corresponds the number of correctly classified observations divided by the total number of observations within the test sample. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "#MNIST dataset:\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#placeholder:\n",
    "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "\n",
    "##Variables:\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def neural_network(input, h_dim):\n",
    "    W0 = weight_variable([784, h_dim])\n",
    "    b0 = bias_variable([h_dim])\n",
    "    h = tf.nn.relu(tf.matmul(input, W0) + b0)\n",
    "\n",
    "    W = weight_variable([h_dim, 10])\n",
    "    b = bias_variable([10])\n",
    "\n",
    "    y = tf.nn.softmax(tf.matmul(h, W) + b)\n",
    "    return y\n",
    "\n",
    "#Network training:\n",
    "def nn_train(learning_rate, h_dim, minibatch = 100):\n",
    "    y = neural_network(x, h_dim)\n",
    "    cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y))\n",
    "    #train_step = tf.train.MomentumOptimizer(learning_rate, 0.5).minimize(cross_entropy)\n",
    "    train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(cross_entropy)\n",
    "    n_samples = len(mnist.train.images)\n",
    "    tf.global_variables_initializer().run()\n",
    "    for _ in range(5000):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(minibatch) #These variables are numpy arrays\n",
    "        sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n",
    "\n",
    "    correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "    return(accuracy.eval(feed_dict={x: mnist.test.images, y_: mnist.test.labels}))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Adquisition Function\n",
    "\n",
    "We start with a gaussian prior on the hyperparameters. We define an adquisicion function that allows us to select a new learning rate to test. In particual we use *expected improvement*. With each new value, we train the network and use the output (the classification accuracy) to update the prior density. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Adquisition function\n",
    "\n",
    "def acquisition_fun(x, y, xn, mean_vector, sigma_vector):\n",
    "    x_best = x[np.argmax(y)]\n",
    "    y_best = np.max(y)\n",
    "    gamma = (mean_vector - y_best)/sigma_vector\n",
    "    af = (mean_vector - y_best)* norm.cdf(gamma) - sigma_vector * norm.pdf(gamma)\n",
    "    x_next = xn[np.argmax(af)]\n",
    "    return x_next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Algorithm\n",
    "\n",
    "\n",
    "Initially, we assume we only observe 2 potential learning rates and their corresponding mean function. We implement an algorithm that, given some prior on the learning rate, at each iteration use the acquisition function to select a new candidate learning rate, trains the network and estimates the posterior density. The plots below show the evolution of the algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roger/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:7: RuntimeWarning: covariance is not positive-semidefinite.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeEAAAFKCAYAAAAqkecjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwGAMBcN/v7EAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff54fdeb6d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Learning rates: [ 0.1  8. ]\n",
      "Accuracy: [0.76789999, 0.91180003]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sess = tf.InteractiveSession()\n",
    "h_dim = 20 # Fixed number of hidden dimensions\n",
    "n = 500 # Number of point in the grid.\n",
    "xn = np.arange(0,10,10/n)\n",
    "\n",
    "l_rates = np.array([0.1,8]) # Initial leeaning rates\n",
    "f = [nn_train(l, h_dim) for l in l_rates] #Accuracy\n",
    "\n",
    "m, noise, length, sf = opt_hyparams_noise(l_rates,f)\n",
    "E, cov = gp_posterior(l_rates, f, xn, m, noise, length, sf)\n",
    "data = data_posterior(xn, E, cov)\n",
    "\n",
    "#This plot shows the mean and variance with two initial observations: \n",
    "plt.plot(data['x'],data['Mean'], color = 'black', label = 'Mean')\n",
    "plt.plot(l_rates,f, 'ro', label = 'Obs')\n",
    "plt.fill_between(data['x'], data['Mean']-data['StdDev'], data['Mean']+data['StdDev'],color = 'lightgrey')\n",
    "plt.show()\n",
    "\n",
    "print ('Initial Learning rates:', l_rates)\n",
    "print ('Accuracy:', f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now we perform 5 interations and observe the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roger/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:7: RuntimeWarning: covariance is not positive-semidefinite.\n"
     ]
    }
   ],
   "source": [
    "#If sf is used, we have to use opt_hyparams_noise, otherwise use opt_hyparams. \n",
    "n_iter = 5\n",
    "\n",
    "for i in range(n_iter):    \n",
    "    next_candidate = acquisition_fun(l_rates, f, xn, np.array(data['Mean']), np.array(data['StdDev']))\n",
    "    l_rates = np.append(l_rates,next_candidate)\n",
    "    f = np.append(f,nn_train(next_candidate, h_dim))\n",
    "    E, cov = gp_posterior(l_rates, f, xn, m, noise, length, sf)\n",
    "    data = data_posterior(xn, E, cov)\n",
    "\n",
    "    try:\n",
    "        m, noise, length, sf = opt_hyparams_noise(l_rates,f)\n",
    "    except ValueError:\n",
    "        m, noise, length, sf = m, noise, length, sf\n",
    "\n",
    "\n",
    "plt.plot(data['x'],data['Mean'], color = 'black', label = 'Mean')\n",
    "plt.plot(l_rates,f, 'ro', label = 'Obs')\n",
    "plt.fill_between(data['x'], data['Mean']-data['StdDev'], data['Mean']+data['StdDev'],color = 'lightgrey')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
